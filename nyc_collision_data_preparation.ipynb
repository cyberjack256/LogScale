{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "> Before diving into the analysis, it's essential to clean and preprocess the data. In this section, we will:\n",
    "\n",
    "1. **Load the data** from the source file.\n",
    "\n",
    "2. **Inspect** the data for missing or incorrect values.\n",
    "\n",
    "3. **Clean** the data by handling missing or incorrect values, and standardize formats.\n",
    "\n",
    "4. **Transform** the data, if necessary, to create new features or better representations of existing features for our analysis.\n",
    "\n",
    "> By carefully preparing the data, we can ensure that our analysis is accurate and reliable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Fields for Time-based Analysis to Reduce Critical Traffic Collisions\n",
    "\n",
    "The following fields have been selected for their relevance in conducting a time-based analysis with the goal of reducing critical traffic collisions by 10%. Understanding the trends and patterns in these fields can help inform data-driven policies and initiatives aimed at reducing traffic fatalities and injuries.\n",
    "\n",
    "| Column Name                   | Description                                                | Type        |\n",
    "|-------------------------------|------------------------------------------------------------|-------------|\n",
    "| CRASH DATE                    | Occurrence date of collision                               | Date & Time |\n",
    "| CRASH TIME                    | Occurrence time of collision                               | Plain Text  |\n",
    "| BOROUGH                       | Borough where collision occurred                           | Plain Text  |\n",
    "| LATITUDE                      | Latitude coordinate for Global Coordinate System           | Number      |\n",
    "| LONGITUDE                     | Longitude coordinate for Global Coordinate System          | Number      |\n",
    "| NUMBER OF PERSONS INJURED     | Number of persons injured                                  | Number      |\n",
    "| NUMBER OF PERSONS KILLED      | Number of persons killed                                   | Number      |\n",
    "| NUMBER OF PEDESTRIANS INJURED | Number of pedestrians injured                              | Number      |\n",
    "| NUMBER OF PEDESTRIANS KILLED  | Number of pedestrians killed                               | Number      |\n",
    "| NUMBER OF CYCLIST INJURED     | Number of cyclists injured                                 | Number      |\n",
    "| NUMBER OF CYCLIST KILLED      | Number of cyclists killed                                  | Number      |\n",
    "| NUMBER OF MOTORIST INJURED    | Number of vehicle occupants injured                        | Number      |\n",
    "| NUMBER OF MOTORIST KILLED     | Number of vehicle occupants killed                         | Number      |\n",
    "| CONTRIBUTING FACTOR VEHICLE 1 | Factors contributing to the collision for designated vehicle| Plain Text  |\n",
    "| CONTRIBUTING FACTOR VEHICLE 2 | Factors contributing to the collision for designated vehicle| Plain Text  |\n",
    "| VEHICLE TYPE CODE 1           | Type of vehicle involved                                   | Plain Text  |\n",
    "| VEHICLE TYPE CODE 2           | Type of vehicle involved                                   | Plain Text  |\n",
    "\n",
    "> **CRASH DATE and CRASH TIME**: \n",
    "\n",
    "Analyzing the date and time of collisions can reveal patterns, such as specific days of the week or times of the day with higher collision rates. This information can help target interventions and allocate resources effectively.\n",
    "> **BOROUGH, LATITUDE, and LONGITUDE**: \n",
    "\n",
    "Geographical data allows for the identification of high-risk areas and hotspots, as well as the evaluation of local policies and infrastructure.\n",
    "> **NUMBER OF PERSONS INJURED, NUMBER OF PERSONS KILLED, NUMBER OF PEDESTRIANS INJURED, NUMBER OF PEDESTRIANS KILLED, NUMBER OF CYCLIST INJURED, NUMBER OF CYCLIST KILLED, NUMBER OF MOTORIST INJURED, NUMBER OF MOTORIST KILLED**: \n",
    "\n",
    "These fields provide crucial information on the severity of collisions and their impact on different road users. This data can be used to prioritize interventions and track progress towards reducing critical traffic collisions.\n",
    "> **CONTRIBUTING FACTOR VEHICLE 1 and CONTRIBUTING FACTOR VEHICLE 2**: \n",
    "\n",
    "Understanding the factors contributing to collisions is essential for identifying targeted interventions and addressing the root causes of traffic collisions.\n",
    "> **VEHICLE TYPE CODE 1 and VEHICLE TYPE CODE 2**: \n",
    "\n",
    "Vehicle types can play a significant role in the severity and frequency of collisions. Analyzing vehicle type data can help identify specific vehicle types that may be overrepresented in critical traffic collisions and inform interventions tailored to those types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((Codeblock One))\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((Codeblock Two))\n",
    "\n",
    "#Load the NYPD Motor Collisions file\n",
    "df = pd.read_csv(\"/Users/Administrator/Documents/Motor_Vehicle_Collisions_-_Crashes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((Codeblock Three))\n",
    "\n",
    "df.info(verbose = True, show_counts = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyst Notes\n",
    "\n",
    "**Total records:** 1.9 million\n",
    "\n",
    "**Records with Borough and Zip Code info:** 1.3 million\n",
    "\n",
    "This means we're missing location records (Borough and Zip Code) for approximately 600k+ entries, or ~30% of the data.\n",
    "\n",
    "> **Note:** We could potentially use reverse geocoding with the `GeoPY` library to find the address (Borough and Zip Code) for records that have a location (Latitude and Longitude). However, this process is time-consuming and may not be feasible for this exercise. As a result, we won't be conducting reverse geocoding in our analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyst Notes\n",
    "## Renaming Fields for Consistency\n",
    "To ensure that our dataset aligns with our internal data model and follows a common structure, we will rename certain fields. This will make it easier to integrate our analysis with other data sources and facilitate collaboration across teams.\n",
    "\n",
    ">Follow these steps to rename fields:\n",
    "\n",
    "Review the current field names and compare them with the internal data model's requirements.\n",
    "Identify any discrepancies or inconsistencies in field names.\n",
    "Rename the fields to match the internal data model, ensuring that they adhere to a common naming convention.\n",
    "By standardizing field names, we can improve data quality and make our analysis more efficient and reliable.\n",
    "\n",
    "> **Note:** Remember to document any changes made to field names, as this will help maintain transparency and facilitate future data management tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((Codeblock Four))\n",
    "\n",
    "df.rename(columns = {  'CRASH DATE' : 'date',\n",
    "                       'CRASH TIME' : 'time',\n",
    "                       'COLLISION_ID' : 'collision_id',\n",
    "                       'BOROUGH' : 'borough',\n",
    "                       'ZIP CODE' : 'zip_code',\n",
    "                       'LATITUDE' : 'latitude',\n",
    "                       'LONGITUDE' : 'longitude',\n",
    "                       'LOCATION' : 'location',\n",
    "                       'ON STREET NAME'    : 'street_on',\n",
    "                       'CROSS STREET NAME' : 'street_cross',\n",
    "                       'OFF STREET NAME'   : 'street_off',\n",
    "                       'NUMBER OF PERSONS INJURED'     : 'total_injured',\n",
    "                       'NUMBER OF PERSONS KILLED'      : 'total_fatality',\n",
    "                       'NUMBER OF PEDESTRIANS INJURED' : 'ped_injured',\n",
    "                       'NUMBER OF PEDESTRIANS KILLED'  : 'ped_fatality',\n",
    "                       'NUMBER OF CYCLIST INJURED'     : 'cyc_injured',\n",
    "                       'NUMBER OF CYCLIST KILLED'      : 'cyc_fatality',\n",
    "                       'NUMBER OF MOTORIST INJURED'    : 'moto_injured',\n",
    "                       'NUMBER OF MOTORIST KILLED'     : 'moto_fatality',\n",
    "                       'CONTRIBUTING FACTOR VEHICLE 1' : 'veh_factor_1',\n",
    "                       'CONTRIBUTING FACTOR VEHICLE 2' : 'veh_factor_2',\n",
    "                       'CONTRIBUTING FACTOR VEHICLE 3' : 'veh_factor_3',\n",
    "                       'CONTRIBUTING FACTOR VEHICLE 4' : 'veh_factor_4',\n",
    "                       'CONTRIBUTING FACTOR VEHICLE 5' : 'veh_factor_5',\n",
    "                       'UNIQUE KEY' : 'unique_key',\n",
    "                       'VEHICLE TYPE CODE 1' : 'veh_type_1',\n",
    "                       'VEHICLE TYPE CODE 2' : 'veh_type_2',\n",
    "                       'VEHICLE TYPE CODE 3' : 'veh_type_3',\n",
    "                       'VEHICLE TYPE CODE 4' : 'veh_type_4',\n",
    "                       'VEHICLE TYPE CODE 5' : 'veh_type_5'},\n",
    "           inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((Codeblock Five))\n",
    "\n",
    "# Find all the keys with missing values and validate our data model changes\n",
    "df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyst Notes\n",
    "\n",
    "> Assign missing Borough records to the value of 'NYC'\n",
    "\n",
    "Borough and Zip Code are missing for ~600k records, which is ~30% of the data. This is a significant portion, so we can't disregard it. We'll have 5 boroughs plus 'NYC' to tag the data with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((Codeblock Six))\n",
    "\n",
    "# Fill all blank values in column Borough\n",
    "# If a value is NaN it will be NYC\n",
    "df.loc[df['borough'].isnull(), 'borough'] = 'NYC'\n",
    "\n",
    "# View the output;`borough` should have 0 NaN values\n",
    "df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyst Notes\n",
    " \n",
    "> Filter Out Total Injured and Total Fatality NaN values\n",
    "\n",
    "We should only keep records where the total number of injured and killed is greater than 0. This will ensure that we're focusing on relevant incidents in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((Codeblock Seven))\n",
    "\n",
    "# Remove NaN from TOTAL INJURED\n",
    "df = df.dropna(axis=0, subset=['total_injured'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((Codeblock Eight))\n",
    "\n",
    "# Remove NaN from TOTAL KILLED\n",
    "df = df.dropna(axis=0, subset=['total_fatality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((Codeblock Nine))\n",
    "\n",
    "# If we are interested in collisions that have injuries, then we may  want to keep those values > 0 as df1\n",
    "df1 = df[(df['total_injured'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((Codeblock Ten))\n",
    "\n",
    "# If we are interested in the collisions that have fatalities, then we may want to keep those values > 0 as df2\n",
    "df2 = df[(df['total_fatality'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((Codeblock Eleven))\n",
    "\n",
    "# To keep only those records with either injuries or fatalities we can  now concatenate df1 and df2 and put it back as df\n",
    "df = pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((Codeblock Twelve))\n",
    "\n",
    "# Combine DATE and TIME column to transform Series to DateTime needed for further analysis\n",
    "df['date'] = df['date'] + ' ' + df['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((Codeblock Thirteen))\n",
    "\n",
    "# Convert string to DateTime\n",
    "df['date'] = pd.to_datetime(df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((Codeblock Fourteen))\n",
    "\n",
    "# Year filter\n",
    "df['year'] = pd.to_datetime(df['date']).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((Codeblock Fifteen))\n",
    "\n",
    "# Quarter filter\n",
    "df['quarter'] = pd.to_datetime(df['date']).dt.quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((Codeblock Sixteen))\n",
    "\n",
    "# Month filter\n",
    "df['month'] = pd.to_datetime(df['date']).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((Codeblock Seventeen))\n",
    "\n",
    "# Day of the week filter\n",
    "df['weekday'] = pd.to_datetime(df['date']).dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((Codeblock Eighteen))\n",
    "\n",
    "#Fill in missing values with Empty\n",
    "df = df.fillna(value='EMPTY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((Codeblock Nineteenth))\n",
    "\n",
    "# Validate the final dataset before analysis\n",
    "df.info(verbose = True, show_counts = True)\n",
    "# We have ~430k relevant records instead of 1.9 million and our file is ~100 MB from ~400 MB at the beginning of preparation\n",
    "# This file is in a much better state to ingest into LogScale and begin working with a sample of the data.\n",
    "# Additionally, we have are steps to clean the data within LogScale via parser as ingest is streaming via API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((Codeblock Twenty))\n",
    "\n",
    "# Save the cleaned dataframe to a new CSV File\n",
    "df.to_csv(\"/Users/Administrator/Documents/clean_nyc_collisions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "log20",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
